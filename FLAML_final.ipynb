{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ds330wkguys/project_code/blob/main/FLAML_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm6AjHyRZcbU"
      },
      "source": [
        "## **FLAML AutoML Time Series Forecasting Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwx9e1xLonpU"
      },
      "source": [
        "# **Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6lRoMX7NEAs",
        "outputId": "9f9f1ca9-f6a6-4a82-e01b-26bef06b2550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flaml[ts_forecast]\n",
            "  Downloading FLAML-1.0.14-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (1.3.5)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (0.90)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (1.0.2)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (1.7.3)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (1.21.6)\n",
            "Collecting hcrystalball==0.1.10\n",
            "  Downloading hcrystalball-0.1.10-py2.py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting holidays<0.14\n",
            "  Downloading holidays-0.13-py3-none-any.whl (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prophet>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (1.1.1)\n",
            "Requirement already satisfied: statsmodels>=0.12.2 in /usr/local/lib/python3.8/dist-packages (from flaml[ts_forecast]) (0.12.2)\n",
            "Collecting workalendar>=10.1\n",
            "  Downloading workalendar-16.4.0-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from hcrystalball==0.1.10->flaml[ts_forecast]) (3.2.2)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from holidays<0.14->flaml[ts_forecast]) (2.4.0)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.8/dist-packages (from holidays<0.14->flaml[ts_forecast]) (2.2.4)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.8/dist-packages (from holidays<0.14->flaml[ts_forecast]) (0.3.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from holidays<0.14->flaml[ts_forecast]) (2.8.2)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.8/dist-packages (from convertdate>=2.3.0->holidays<0.14->flaml[ts_forecast]) (0.5.11)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->flaml[ts_forecast]) (0.38.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->flaml[ts_forecast]) (2022.6)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.0.1->flaml[ts_forecast]) (1.2)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.0.1->flaml[ts_forecast]) (4.64.1)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.0.1->flaml[ts_forecast]) (57.4.0)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.0.1->flaml[ts_forecast]) (1.0.8)\n",
            "Collecting prophet>=1.0.1\n",
            "  Downloading prophet-1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.0.1->flaml[ts_forecast]) (0.29.32)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.8/dist-packages (from prophet>=1.0.1->flaml[ts_forecast]) (0.0.9)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.8/dist-packages (from LunarCalendar>=0.0.9->prophet>=1.0.1->flaml[ts_forecast]) (4.1.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->hcrystalball==0.1.10->flaml[ts_forecast]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->hcrystalball==0.1.10->flaml[ts_forecast]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->hcrystalball==0.1.10->flaml[ts_forecast]) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->holidays<0.14->flaml[ts_forecast]) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->flaml[ts_forecast]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->flaml[ts_forecast]) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.12.2->flaml[ts_forecast]) (0.5.3)\n",
            "Collecting lunardate\n",
            "  Downloading lunardate-0.2.0-py3-none-any.whl (5.6 kB)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.0.2-py3-none-any.whl (22 kB)\n",
            "Collecting backports.zoneinfo\n",
            "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-manylinux1_x86_64.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 1.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyluach, lunardate, backports.zoneinfo, workalendar, lightgbm, holidays, prophet, hcrystalball, flaml\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: holidays\n",
            "    Found existing installation: holidays 0.17\n",
            "    Uninstalling holidays-0.17:\n",
            "      Successfully uninstalled holidays-0.17\n",
            "  Attempting uninstall: prophet\n",
            "    Found existing installation: prophet 1.1.1\n",
            "    Uninstalling prophet-1.1.1:\n",
            "      Successfully uninstalled prophet-1.1.1\n",
            "Successfully installed backports.zoneinfo-0.2.1 flaml-1.0.14 hcrystalball-0.1.10 holidays-0.13 lightgbm-3.3.3 lunardate-0.2.0 prophet-1.1 pyluach-2.0.2 workalendar-16.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"flaml[ts_forecast]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwpVZhrUobJV"
      },
      "source": [
        "# **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCJXfpiYM_Kk",
        "outputId": "fd2e01db-9e17-4d27-f1f2-5c7510189457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SChjAHTLNKxm",
        "outputId": "c536e388-61ac-4667-df99-5cd1061c5346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date     MarketCap  EnterpriseValue  PeRatio  sentimental       Price\n",
              "0  2021-09-22  5.179000e+11     5.110370e+11   74.118     0.190943  219.410004\n",
              "1  2021-09-23  5.179000e+11     5.110370e+11   74.118     0.113162  224.820007\n",
              "2  2021-09-24  5.179000e+11     5.110370e+11   74.118     0.123634  220.809998\n",
              "3  2021-09-25  5.179000e+11     5.110370e+11   74.118     0.125748  219.406667\n",
              "4  2021-09-26  5.179000e+11     5.110370e+11   74.118     0.124486  218.003337\n",
              "5  2021-09-27  5.179000e+11     5.110370e+11   74.118     0.131136  216.600006\n",
              "6  2021-09-28  5.179000e+11     5.110370e+11   74.118     0.137007  206.990005\n",
              "7  2021-09-29  5.179000e+11     5.110370e+11   74.118     0.125239  205.169998\n",
              "8  2021-09-30  5.179000e+11     5.110370e+11   74.118     0.151043  207.160004\n",
              "9  2021-10-01  6.391750e+11     6.323120e+11   87.407     0.110076  207.419998"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7970dc2e-2e55-47ec-8031-e1d529352119\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>MarketCap</th>\n",
              "      <th>EnterpriseValue</th>\n",
              "      <th>PeRatio</th>\n",
              "      <th>sentimental</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-22</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.190943</td>\n",
              "      <td>219.410004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-09-23</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.113162</td>\n",
              "      <td>224.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-09-24</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.123634</td>\n",
              "      <td>220.809998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-09-25</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.125748</td>\n",
              "      <td>219.406667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-09-26</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.124486</td>\n",
              "      <td>218.003337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-09-27</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.131136</td>\n",
              "      <td>216.600006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-09-28</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.137007</td>\n",
              "      <td>206.990005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2021-09-29</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.125239</td>\n",
              "      <td>205.169998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>5.179000e+11</td>\n",
              "      <td>5.110370e+11</td>\n",
              "      <td>74.118</td>\n",
              "      <td>0.151043</td>\n",
              "      <td>207.160004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>6.391750e+11</td>\n",
              "      <td>6.323120e+11</td>\n",
              "      <td>87.407</td>\n",
              "      <td>0.110076</td>\n",
              "      <td>207.419998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7970dc2e-2e55-47ec-8031-e1d529352119')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7970dc2e-2e55-47ec-8031-e1d529352119 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7970dc2e-2e55-47ec-8031-e1d529352119');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df_NVDA = pd.read_csv(\"/content/drive/MyDrive/2022 fall DS440/data/NVDA_merged.csv\")    # Read csv from the directory\n",
        "\n",
        "# Make sure there is no missing dates\n",
        "#df_NVDA['Date'] = pd.to_datetime(df_NVDA['Date'])\n",
        "#df_NVDA = df_NVDA.set_index('Date')    # Changing index for Filling values\n",
        "\n",
        "#df_NVDA = df_NVDA.resample('D').first()    # Resampling & Assigning values\n",
        "#df_NVDA = df_NVDA.bfill().ffill()\n",
        "\n",
        "#df_NVDA.reset_index(inplace=True)    # Resetting the index after filling values\n",
        "\n",
        "df_NVDA.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr6ocQ2Jo0eF"
      },
      "source": [
        "# **Splitting Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = df_NVDA.shape[0]\n",
        "\n",
        "time_horizon = 50\n",
        "split_idx = num_samples - time_horizon\n",
        "# df_TSLA = df_TSLA[:split_idx]  # train_df is a dataframe with two columns: timestamp and label\n",
        "x_test = df_NVDA.iloc[split_idx:,0:5]\n",
        "y_test = df_NVDA[split_idx:]['Price']\n",
        "\n",
        "train_NVDA = df_NVDA.iloc[:split_idx]\n",
        "train_NVDA2 = train_NVDA.drop(['MarketCap', 'EnterpriseValue', 'PeRatio', 'sentimental'], axis = 1)\n",
        "train_NVDA2.info()"
      ],
      "metadata": {
        "id": "ErcpK5XyKdfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e4ef09-f736-43b8-f9b8-f2e09b942772"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 292 entries, 0 to 291\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Date    292 non-null    object \n",
            " 1   Price   292 non-null    float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 4.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_NVDA2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hPeRWlCI8e8",
        "outputId": "00e2e433-b3e4-400d-e38b-2a30d38b59a4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 292 entries, 0 to 291\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   Date    292 non-null    datetime64[ns]\n",
            " 1   Price   292 non-null    float64       \n",
            "dtypes: datetime64[ns](1), float64(1)\n",
            "memory usage: 4.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_NVDA.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSLJ32mpWaO9",
        "outputId": "6cfc81c7-284a-4ff8-9de0-bce6630a0e96"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 292 entries, 0 to 291\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype         \n",
            "---  ------           --------------  -----         \n",
            " 0   Date             292 non-null    datetime64[ns]\n",
            " 1   MarketCap        292 non-null    float64       \n",
            " 2   EnterpriseValue  292 non-null    float64       \n",
            " 3   PeRatio          292 non-null    float64       \n",
            " 4   sentimental      292 non-null    float64       \n",
            " 5   Price            292 non-null    float64       \n",
            "dtypes: datetime64[ns](1), float64(5)\n",
            "memory usage: 13.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oLhp67_piEF"
      },
      "source": [
        "# **Building a Time Series Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RwI6bpgU7Tl",
        "outputId": "6dc03165-510d-434d-fefe-7835dacc57f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-04 22:56:03] {2599} INFO - task = ts_forecast\n",
            "INFO:flaml.automl:task = ts_forecast\n",
            "[flaml.automl: 12-04 22:56:03] {2601} INFO - Data split method: time\n",
            "INFO:flaml.automl:Data split method: time\n",
            "[flaml.automl: 12-04 22:56:03] {2604} INFO - Evaluation method: cv\n",
            "INFO:flaml.automl:Evaluation method: cv\n",
            "[flaml.automl: 12-04 22:56:03] {2726} INFO - Minimizing error metric: mape\n",
            "INFO:flaml.automl:Minimizing error metric: mape\n",
            "[flaml.automl: 12-04 22:56:03] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'prophet', 'arima', 'sarimax']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'prophet', 'arima', 'sarimax']\n",
            "[flaml.automl: 12-04 22:56:03] {3166} INFO - iteration 0, current learner lgbm\n",
            "INFO:flaml.automl:iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:03] {3296} INFO - Estimated sufficient time budget=919s. Estimated necessary time budget=1s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=919s. Estimated necessary time budget=1s.\n",
            "[flaml.automl: 12-04 22:56:03] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.3750,\tbest estimator lgbm's best error=0.3750\n",
            "INFO:flaml.automl: at 0.1s,\testimator lgbm's best error=0.3750,\tbest estimator lgbm's best error=0.3750\n",
            "[flaml.automl: 12-04 22:56:03] {3166} INFO - iteration 1, current learner lgbm\n",
            "INFO:flaml.automl:iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:03] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.3113,\tbest estimator lgbm's best error=0.3113\n",
            "INFO:flaml.automl: at 0.2s,\testimator lgbm's best error=0.3113,\tbest estimator lgbm's best error=0.3113\n",
            "[flaml.automl: 12-04 22:56:03] {3166} INFO - iteration 2, current learner rf\n",
            "INFO:flaml.automl:iteration 2, current learner rf\n",
            "[flaml.automl: 12-04 22:56:04] {3343} INFO -  at 0.4s,\testimator rf's best error=0.1149,\tbest estimator rf's best error=0.1149\n",
            "INFO:flaml.automl: at 0.4s,\testimator rf's best error=0.1149,\tbest estimator rf's best error=0.1149\n",
            "[flaml.automl: 12-04 22:56:04] {3166} INFO - iteration 3, current learner xgboost\n",
            "INFO:flaml.automl:iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:04] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.6271,\tbest estimator rf's best error=0.1149\n",
            "INFO:flaml.automl: at 0.5s,\testimator xgboost's best error=0.6271,\tbest estimator rf's best error=0.1149\n",
            "[flaml.automl: 12-04 22:56:04] {3166} INFO - iteration 4, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 4, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:04] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.1024,\tbest estimator extra_tree's best error=0.1024\n",
            "INFO:flaml.automl: at 0.6s,\testimator extra_tree's best error=0.1024,\tbest estimator extra_tree's best error=0.1024\n",
            "[flaml.automl: 12-04 22:56:04] {3166} INFO - iteration 5, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 5, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:04] {3343} INFO -  at 0.8s,\testimator xgb_limitdepth's best error=0.0338,\tbest estimator xgb_limitdepth's best error=0.0338\n",
            "INFO:flaml.automl: at 0.8s,\testimator xgb_limitdepth's best error=0.0338,\tbest estimator xgb_limitdepth's best error=0.0338\n",
            "[flaml.automl: 12-04 22:56:04] {3166} INFO - iteration 6, current learner prophet\n",
            "INFO:flaml.automl:iteration 6, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/i_nmdpeu.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/3jqnh_ir.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=25949', 'data', 'file=/tmp/tmp5v0rfnlj/i_nmdpeu.json', 'init=/tmp/tmp5v0rfnlj/3jqnh_ir.json', 'output', 'file=/tmp/tmp2p5hm9b7/prophet_model-20221204225604.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:04 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:04 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/i0kvsp36.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/6dqg10up.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=94102', 'data', 'file=/tmp/tmp5v0rfnlj/i0kvsp36.json', 'init=/tmp/tmp5v0rfnlj/6dqg10up.json', 'output', 'file=/tmp/tmp1jpkguk4/prophet_model-20221204225606.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:06 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/iabfwlru.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/m1fvajph.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=87806', 'data', 'file=/tmp/tmp5v0rfnlj/iabfwlru.json', 'init=/tmp/tmp5v0rfnlj/m1fvajph.json', 'output', 'file=/tmp/tmp1otey0l_/prophet_model-20221204225607.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:07 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:07 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/a4ozw8_x.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/bik8m7si.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=51003', 'data', 'file=/tmp/tmp5v0rfnlj/a4ozw8_x.json', 'init=/tmp/tmp5v0rfnlj/bik8m7si.json', 'output', 'file=/tmp/tmpmbshts04/prophet_model-20221204225608.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:08 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:08 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/g40i7tr9.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/ckbv611l.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=19331', 'data', 'file=/tmp/tmp5v0rfnlj/g40i7tr9.json', 'init=/tmp/tmp5v0rfnlj/ckbv611l.json', 'output', 'file=/tmp/tmpxo4gagul/prophet_model-20221204225610.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:10 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:10 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 12-04 22:56:11] {3343} INFO -  at 7.6s,\testimator prophet's best error=0.0665,\tbest estimator xgb_limitdepth's best error=0.0338\n",
            "INFO:flaml.automl: at 7.6s,\testimator prophet's best error=0.0665,\tbest estimator xgb_limitdepth's best error=0.0338\n",
            "[flaml.automl: 12-04 22:56:11] {3166} INFO - iteration 7, current learner arima\n",
            "INFO:flaml.automl:iteration 7, current learner arima\n",
            "[flaml.automl: 12-04 22:56:11] {3343} INFO -  at 8.2s,\testimator arima's best error=0.0178,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 8.2s,\testimator arima's best error=0.0178,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:11] {3166} INFO - iteration 8, current learner sarimax\n",
            "INFO:flaml.automl:iteration 8, current learner sarimax\n",
            "[flaml.automl: 12-04 22:56:17] {3343} INFO -  at 14.1s,\testimator sarimax's best error=0.0204,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.1s,\testimator sarimax's best error=0.0204,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:17] {3166} INFO - iteration 9, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 9, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:17] {3343} INFO -  at 14.2s,\testimator xgb_limitdepth's best error=0.0300,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.2s,\testimator xgb_limitdepth's best error=0.0300,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:17] {3166} INFO - iteration 10, current learner lgbm\n",
            "INFO:flaml.automl:iteration 10, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 14.3s,\testimator lgbm's best error=0.3113,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.3s,\testimator lgbm's best error=0.3113,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 11, current learner xgboost\n",
            "INFO:flaml.automl:iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 14.4s,\testimator xgboost's best error=0.4562,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.4s,\testimator xgboost's best error=0.4562,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 12, current learner rf\n",
            "INFO:flaml.automl:iteration 12, current learner rf\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 14.6s,\testimator rf's best error=0.1149,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.6s,\testimator rf's best error=0.1149,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 13, current learner rf\n",
            "INFO:flaml.automl:iteration 13, current learner rf\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 14.7s,\testimator rf's best error=0.0539,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.7s,\testimator rf's best error=0.0539,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 14, current learner rf\n",
            "INFO:flaml.automl:iteration 14, current learner rf\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 14.9s,\testimator rf's best error=0.0269,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 14.9s,\testimator rf's best error=0.0269,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 15, current learner rf\n",
            "INFO:flaml.automl:iteration 15, current learner rf\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 15.0s,\testimator rf's best error=0.0269,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.0s,\testimator rf's best error=0.0269,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 16, current learner xgboost\n",
            "INFO:flaml.automl:iteration 16, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 15.1s,\testimator xgboost's best error=0.4562,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.1s,\testimator xgboost's best error=0.4562,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 17, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 17, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:18] {3343} INFO -  at 15.3s,\testimator extra_tree's best error=0.1024,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.3s,\testimator extra_tree's best error=0.1024,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:18] {3166} INFO - iteration 18, current learner rf\n",
            "INFO:flaml.automl:iteration 18, current learner rf\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 15.4s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.4s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 19, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 19, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 15.5s,\testimator xgb_limitdepth's best error=0.0300,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.5s,\testimator xgb_limitdepth's best error=0.0300,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 20, current learner rf\n",
            "INFO:flaml.automl:iteration 20, current learner rf\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 15.7s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.7s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 21, current learner arima\n",
            "INFO:flaml.automl:iteration 21, current learner arima\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 15.8s,\testimator arima's best error=0.0178,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.8s,\testimator arima's best error=0.0178,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 22, current learner lgbm\n",
            "INFO:flaml.automl:iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 15.9s,\testimator lgbm's best error=0.3113,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 15.9s,\testimator lgbm's best error=0.3113,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 23, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 23, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 16.0s,\testimator xgb_limitdepth's best error=0.0300,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 16.0s,\testimator xgb_limitdepth's best error=0.0300,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 24, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 24, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 16.1s,\testimator extra_tree's best error=0.0567,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 16.1s,\testimator extra_tree's best error=0.0567,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 25, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:19] {3343} INFO -  at 16.2s,\testimator extra_tree's best error=0.0335,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 16.2s,\testimator extra_tree's best error=0.0335,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:19] {3166} INFO - iteration 26, current learner xgboost\n",
            "INFO:flaml.automl:iteration 26, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:20] {3343} INFO -  at 16.3s,\testimator xgboost's best error=0.3034,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 16.3s,\testimator xgboost's best error=0.3034,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:20] {3166} INFO - iteration 27, current learner xgboost\n",
            "INFO:flaml.automl:iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:20] {3343} INFO -  at 16.4s,\testimator xgboost's best error=0.3034,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 16.4s,\testimator xgboost's best error=0.3034,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:20] {3166} INFO - iteration 28, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 28, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:20] {3343} INFO -  at 16.5s,\testimator xgb_limitdepth's best error=0.0287,\tbest estimator arima's best error=0.0178\n",
            "INFO:flaml.automl: at 16.5s,\testimator xgb_limitdepth's best error=0.0287,\tbest estimator arima's best error=0.0178\n",
            "[flaml.automl: 12-04 22:56:20] {3166} INFO - iteration 29, current learner arima\n",
            "INFO:flaml.automl:iteration 29, current learner arima\n",
            "[flaml.automl: 12-04 22:56:20] {3343} INFO -  at 17.1s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 17.1s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:20] {3166} INFO - iteration 30, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 30, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:20] {3343} INFO -  at 17.2s,\testimator extra_tree's best error=0.0335,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 17.2s,\testimator extra_tree's best error=0.0335,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:20] {3166} INFO - iteration 31, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 31, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:21] {3343} INFO -  at 17.3s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 17.3s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:21] {3166} INFO - iteration 32, current learner arima\n",
            "INFO:flaml.automl:iteration 32, current learner arima\n",
            "[flaml.automl: 12-04 22:56:21] {3343} INFO -  at 17.7s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 17.7s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:21] {3166} INFO - iteration 33, current learner arima\n",
            "INFO:flaml.automl:iteration 33, current learner arima\n",
            "[flaml.automl: 12-04 22:56:21] {3343} INFO -  at 18.0s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 18.0s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:21] {3166} INFO - iteration 34, current learner rf\n",
            "INFO:flaml.automl:iteration 34, current learner rf\n",
            "[flaml.automl: 12-04 22:56:21] {3343} INFO -  at 18.1s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 18.1s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:21] {3166} INFO - iteration 35, current learner lgbm\n",
            "INFO:flaml.automl:iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:21] {3343} INFO -  at 18.2s,\testimator lgbm's best error=0.1193,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 18.2s,\testimator lgbm's best error=0.1193,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:21] {3166} INFO - iteration 36, current learner lgbm\n",
            "INFO:flaml.automl:iteration 36, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:22] {3343} INFO -  at 18.3s,\testimator lgbm's best error=0.1193,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 18.3s,\testimator lgbm's best error=0.1193,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:22] {3166} INFO - iteration 37, current learner arima\n",
            "INFO:flaml.automl:iteration 37, current learner arima\n",
            "[flaml.automl: 12-04 22:56:22] {3343} INFO -  at 18.9s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 18.9s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:22] {3166} INFO - iteration 38, current learner lgbm\n",
            "INFO:flaml.automl:iteration 38, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:22] {3343} INFO -  at 19.0s,\testimator lgbm's best error=0.0216,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.0s,\testimator lgbm's best error=0.0216,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:22] {3166} INFO - iteration 39, current learner lgbm\n",
            "INFO:flaml.automl:iteration 39, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:22] {3343} INFO -  at 19.1s,\testimator lgbm's best error=0.0216,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.1s,\testimator lgbm's best error=0.0216,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:22] {3166} INFO - iteration 40, current learner arima\n",
            "INFO:flaml.automl:iteration 40, current learner arima\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 19.4s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.4s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 41, current learner lgbm\n",
            "INFO:flaml.automl:iteration 41, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 19.5s,\testimator lgbm's best error=0.0180,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.5s,\testimator lgbm's best error=0.0180,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 42, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 42, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 19.6s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.6s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 43, current learner lgbm\n",
            "INFO:flaml.automl:iteration 43, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 19.7s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.7s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 44, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 44, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 19.9s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 19.9s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 45, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 45, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 20.0s,\testimator xgb_limitdepth's best error=0.0287,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 20.0s,\testimator xgb_limitdepth's best error=0.0287,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 46, current learner lgbm\n",
            "INFO:flaml.automl:iteration 46, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 20.1s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 20.1s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 47, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 47, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:23] {3343} INFO -  at 20.2s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 20.2s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:23] {3166} INFO - iteration 48, current learner sarimax\n",
            "INFO:flaml.automl:iteration 48, current learner sarimax\n",
            "[flaml.automl: 12-04 22:56:27] {3343} INFO -  at 23.3s,\testimator sarimax's best error=0.0204,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 23.3s,\testimator sarimax's best error=0.0204,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:27] {3166} INFO - iteration 49, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 49, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:27] {3343} INFO -  at 23.4s,\testimator xgb_limitdepth's best error=0.0283,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 23.4s,\testimator xgb_limitdepth's best error=0.0283,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:27] {3166} INFO - iteration 50, current learner rf\n",
            "INFO:flaml.automl:iteration 50, current learner rf\n",
            "[flaml.automl: 12-04 22:56:27] {3343} INFO -  at 23.6s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 23.6s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:27] {3166} INFO - iteration 51, current learner prophet\n",
            "INFO:flaml.automl:iteration 51, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/wr3pz8vo.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/iuabqy8s.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=16757', 'data', 'file=/tmp/tmp5v0rfnlj/wr3pz8vo.json', 'init=/tmp/tmp5v0rfnlj/iuabqy8s.json', 'output', 'file=/tmp/tmpg0g63e7y/prophet_model-20221204225627.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:27 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:27 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/x8kd9cp0.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/htjkwml4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=18611', 'data', 'file=/tmp/tmp5v0rfnlj/x8kd9cp0.json', 'init=/tmp/tmp5v0rfnlj/htjkwml4.json', 'output', 'file=/tmp/tmp_xme0ez1/prophet_model-20221204225628.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:28 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:28 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/swis_jml.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/mrppa4u9.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=87359', 'data', 'file=/tmp/tmp5v0rfnlj/swis_jml.json', 'init=/tmp/tmp5v0rfnlj/mrppa4u9.json', 'output', 'file=/tmp/tmp6z8_8s1w/prophet_model-20221204225629.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:29 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:29 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/5devuy6n.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/t0rkq8lk.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=3920', 'data', 'file=/tmp/tmp5v0rfnlj/5devuy6n.json', 'init=/tmp/tmp5v0rfnlj/t0rkq8lk.json', 'output', 'file=/tmp/tmpxm6z823y/prophet_model-20221204225630.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:30 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:31 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/55llf4r5.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/lgm8l0ok.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=21847', 'data', 'file=/tmp/tmp5v0rfnlj/55llf4r5.json', 'init=/tmp/tmp5v0rfnlj/lgm8l0ok.json', 'output', 'file=/tmp/tmpp_f6zkv_/prophet_model-20221204225632.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:32 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:32 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 12-04 22:56:33] {3343} INFO -  at 29.6s,\testimator prophet's best error=0.0665,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 29.6s,\testimator prophet's best error=0.0665,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:33] {3166} INFO - iteration 52, current learner lgbm\n",
            "INFO:flaml.automl:iteration 52, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:33] {3343} INFO -  at 29.7s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 29.7s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:33] {3166} INFO - iteration 53, current learner xgboost\n",
            "INFO:flaml.automl:iteration 53, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:33] {3343} INFO -  at 29.8s,\testimator xgboost's best error=0.3034,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 29.8s,\testimator xgboost's best error=0.3034,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:33] {3166} INFO - iteration 54, current learner arima\n",
            "INFO:flaml.automl:iteration 54, current learner arima\n",
            "[flaml.automl: 12-04 22:56:34] {3343} INFO -  at 30.9s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 30.9s,\testimator arima's best error=0.0176,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:34] {3166} INFO - iteration 55, current learner xgboost\n",
            "INFO:flaml.automl:iteration 55, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:34] {3343} INFO -  at 31.0s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.0s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:34] {3166} INFO - iteration 56, current learner xgboost\n",
            "INFO:flaml.automl:iteration 56, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:34] {3343} INFO -  at 31.1s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.1s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:34] {3166} INFO - iteration 57, current learner xgboost\n",
            "INFO:flaml.automl:iteration 57, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:34] {3343} INFO -  at 31.2s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.2s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:34] {3166} INFO - iteration 58, current learner lgbm\n",
            "INFO:flaml.automl:iteration 58, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.3s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.3s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 59, current learner xgboost\n",
            "INFO:flaml.automl:iteration 59, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.4s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.4s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 60, current learner xgboost\n",
            "INFO:flaml.automl:iteration 60, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.5s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.5s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 61, current learner xgboost\n",
            "INFO:flaml.automl:iteration 61, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.6s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.6s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 62, current learner xgboost\n",
            "INFO:flaml.automl:iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.7s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.7s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 63, current learner lgbm\n",
            "INFO:flaml.automl:iteration 63, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.8s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.8s,\testimator lgbm's best error=0.0178,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 64, current learner xgboost\n",
            "INFO:flaml.automl:iteration 64, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 31.9s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 31.9s,\testimator xgboost's best error=0.0266,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 65, current learner rf\n",
            "INFO:flaml.automl:iteration 65, current learner rf\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 32.1s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 32.1s,\testimator rf's best error=0.0236,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 66, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 66, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:35] {3343} INFO -  at 32.2s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 32.2s,\testimator extra_tree's best error=0.0255,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:35] {3166} INFO - iteration 67, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 67, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 32.3s,\testimator extra_tree's best error=0.0204,\tbest estimator arima's best error=0.0176\n",
            "INFO:flaml.automl: at 32.3s,\testimator extra_tree's best error=0.0204,\tbest estimator arima's best error=0.0176\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 68, current learner rf\n",
            "INFO:flaml.automl:iteration 68, current learner rf\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 32.5s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 32.5s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 69, current learner xgboost\n",
            "INFO:flaml.automl:iteration 69, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 32.6s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 32.6s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 70, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 70, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 32.7s,\testimator extra_tree's best error=0.0204,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 32.7s,\testimator extra_tree's best error=0.0204,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 71, current learner xgboost\n",
            "INFO:flaml.automl:iteration 71, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 32.8s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 32.8s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 72, current learner rf\n",
            "INFO:flaml.automl:iteration 72, current learner rf\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 32.9s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 32.9s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 73, current learner xgboost\n",
            "INFO:flaml.automl:iteration 73, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 33.0s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 33.0s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 74, current learner xgboost\n",
            "INFO:flaml.automl:iteration 74, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 33.1s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 33.1s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 75, current learner xgboost\n",
            "INFO:flaml.automl:iteration 75, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:36] {3343} INFO -  at 33.2s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 33.2s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:36] {3166} INFO - iteration 76, current learner prophet\n",
            "INFO:flaml.automl:iteration 76, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/tb1q458j.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/_xy86q72.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=25221', 'data', 'file=/tmp/tmp5v0rfnlj/tb1q458j.json', 'init=/tmp/tmp5v0rfnlj/_xy86q72.json', 'output', 'file=/tmp/tmp6juv4ml4/prophet_model-20221204225636.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/vtcj5mta.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/kpyj18e3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=57692', 'data', 'file=/tmp/tmp5v0rfnlj/vtcj5mta.json', 'init=/tmp/tmp5v0rfnlj/kpyj18e3.json', 'output', 'file=/tmp/tmpx0ai8rvf/prophet_model-20221204225638.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:38 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:38 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/beyqtuij.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/q_5bk9b6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=17354', 'data', 'file=/tmp/tmp5v0rfnlj/beyqtuij.json', 'init=/tmp/tmp5v0rfnlj/q_5bk9b6.json', 'output', 'file=/tmp/tmpovi_49zt/prophet_model-20221204225639.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:39 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:39 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/mz9b9vnn.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/rmngxzc7.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=46372', 'data', 'file=/tmp/tmp5v0rfnlj/mz9b9vnn.json', 'init=/tmp/tmp5v0rfnlj/rmngxzc7.json', 'output', 'file=/tmp/tmp5lbmbf8w/prophet_model-20221204225640.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:40 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:40 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/faf8r2zg.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/_qxd7uqe.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=32321', 'data', 'file=/tmp/tmp5v0rfnlj/faf8r2zg.json', 'init=/tmp/tmp5v0rfnlj/_qxd7uqe.json', 'output', 'file=/tmp/tmpvfulrzhk/prophet_model-20221204225641.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:41 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:41 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 39.4s,\testimator prophet's best error=0.0433,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 39.4s,\testimator prophet's best error=0.0433,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 77, current learner xgboost\n",
            "INFO:flaml.automl:iteration 77, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 39.5s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 39.5s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 78, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 78, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 39.6s,\testimator extra_tree's best error=0.0204,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 39.6s,\testimator extra_tree's best error=0.0204,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 79, current learner rf\n",
            "INFO:flaml.automl:iteration 79, current learner rf\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 39.8s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 39.8s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 80, current learner rf\n",
            "INFO:flaml.automl:iteration 80, current learner rf\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 40.0s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.0s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 81, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 81, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 40.1s,\testimator extra_tree's best error=0.0204,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.1s,\testimator extra_tree's best error=0.0204,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 82, current learner rf\n",
            "INFO:flaml.automl:iteration 82, current learner rf\n",
            "[flaml.automl: 12-04 22:56:43] {3343} INFO -  at 40.3s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.3s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:43] {3166} INFO - iteration 83, current learner rf\n",
            "INFO:flaml.automl:iteration 83, current learner rf\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 40.4s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.4s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 84, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 40.5s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.5s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 85, current learner rf\n",
            "INFO:flaml.automl:iteration 85, current learner rf\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 40.7s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.7s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 40.8s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.8s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 87, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 87, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 40.9s,\testimator extra_tree's best error=0.0195,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 40.9s,\testimator extra_tree's best error=0.0195,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 88, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 41.0s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.0s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 89, current learner xgboost\n",
            "INFO:flaml.automl:iteration 89, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:44] {3343} INFO -  at 41.2s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.2s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:44] {3166} INFO - iteration 90, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 90, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:45] {3343} INFO -  at 41.3s,\testimator extra_tree's best error=0.0195,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.3s,\testimator extra_tree's best error=0.0195,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:45] {3166} INFO - iteration 91, current learner rf\n",
            "INFO:flaml.automl:iteration 91, current learner rf\n",
            "[flaml.automl: 12-04 22:56:45] {3343} INFO -  at 41.5s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.5s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:45] {3166} INFO - iteration 92, current learner rf\n",
            "INFO:flaml.automl:iteration 92, current learner rf\n",
            "[flaml.automl: 12-04 22:56:45] {3343} INFO -  at 41.7s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.7s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:45] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 93, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:45] {3343} INFO -  at 41.8s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.8s,\testimator xgb_limitdepth's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:45] {3166} INFO - iteration 94, current learner xgboost\n",
            "INFO:flaml.automl:iteration 94, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:45] {3343} INFO -  at 41.9s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 41.9s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:45] {3166} INFO - iteration 95, current learner sarimax\n",
            "INFO:flaml.automl:iteration 95, current learner sarimax\n",
            "[flaml.automl: 12-04 22:56:49] {3343} INFO -  at 45.9s,\testimator sarimax's best error=0.0185,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 45.9s,\testimator sarimax's best error=0.0185,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:49] {3166} INFO - iteration 96, current learner xgboost\n",
            "INFO:flaml.automl:iteration 96, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:49] {3343} INFO -  at 46.1s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 46.1s,\testimator xgboost's best error=0.0266,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:49] {3166} INFO - iteration 97, current learner xgboost\n",
            "INFO:flaml.automl:iteration 97, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:49] {3343} INFO -  at 46.2s,\testimator xgboost's best error=0.0239,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 46.2s,\testimator xgboost's best error=0.0239,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:49] {3166} INFO - iteration 98, current learner rf\n",
            "INFO:flaml.automl:iteration 98, current learner rf\n",
            "[flaml.automl: 12-04 22:56:50] {3343} INFO -  at 46.3s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 46.3s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:50] {3166} INFO - iteration 99, current learner arima\n",
            "INFO:flaml.automl:iteration 99, current learner arima\n",
            "[flaml.automl: 12-04 22:56:50] {3343} INFO -  at 47.2s,\testimator arima's best error=0.0176,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 47.2s,\testimator arima's best error=0.0176,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:50] {3166} INFO - iteration 100, current learner rf\n",
            "INFO:flaml.automl:iteration 100, current learner rf\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 47.3s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 47.3s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 101, current learner xgboost\n",
            "INFO:flaml.automl:iteration 101, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 47.4s,\testimator xgboost's best error=0.0239,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 47.4s,\testimator xgboost's best error=0.0239,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 102, current learner rf\n",
            "INFO:flaml.automl:iteration 102, current learner rf\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 47.6s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 47.6s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 103, current learner rf\n",
            "INFO:flaml.automl:iteration 103, current learner rf\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 47.7s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 47.7s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 104, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 104, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 47.8s,\testimator xgb_limitdepth's best error=0.0259,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 47.8s,\testimator xgb_limitdepth's best error=0.0259,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 105, current learner xgboost\n",
            "INFO:flaml.automl:iteration 105, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 48.0s,\testimator xgboost's best error=0.0239,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.0s,\testimator xgboost's best error=0.0239,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 106, current learner lgbm\n",
            "INFO:flaml.automl:iteration 106, current learner lgbm\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 48.1s,\testimator lgbm's best error=0.0178,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.1s,\testimator lgbm's best error=0.0178,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 107, current learner xgboost\n",
            "INFO:flaml.automl:iteration 107, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:51] {3343} INFO -  at 48.2s,\testimator xgboost's best error=0.0225,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.2s,\testimator xgboost's best error=0.0225,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:51] {3166} INFO - iteration 108, current learner rf\n",
            "INFO:flaml.automl:iteration 108, current learner rf\n",
            "[flaml.automl: 12-04 22:56:52] {3343} INFO -  at 48.4s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.4s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:52] {3166} INFO - iteration 109, current learner xgboost\n",
            "INFO:flaml.automl:iteration 109, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:52] {3343} INFO -  at 48.5s,\testimator xgboost's best error=0.0225,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.5s,\testimator xgboost's best error=0.0225,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:52] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 110, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-04 22:56:52] {3343} INFO -  at 48.6s,\testimator xgb_limitdepth's best error=0.0259,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.6s,\testimator xgb_limitdepth's best error=0.0259,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:52] {3166} INFO - iteration 111, current learner rf\n",
            "INFO:flaml.automl:iteration 111, current learner rf\n",
            "[flaml.automl: 12-04 22:56:52] {3343} INFO -  at 48.8s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 48.8s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:52] {3166} INFO - iteration 112, current learner prophet\n",
            "INFO:flaml.automl:iteration 112, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/i8la5mzp.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/5mvx6bo5.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=49966', 'data', 'file=/tmp/tmp5v0rfnlj/i8la5mzp.json', 'init=/tmp/tmp5v0rfnlj/5mvx6bo5.json', 'output', 'file=/tmp/tmps2omoxxw/prophet_model-20221204225652.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/xykovaqh.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/q4o3_cyc.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=64922', 'data', 'file=/tmp/tmp5v0rfnlj/xykovaqh.json', 'init=/tmp/tmp5v0rfnlj/q4o3_cyc.json', 'output', 'file=/tmp/tmp1sd35jb4/prophet_model-20221204225653.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:53 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:53 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/mptw1_fa.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/9yvu8xim.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=49154', 'data', 'file=/tmp/tmp5v0rfnlj/mptw1_fa.json', 'init=/tmp/tmp5v0rfnlj/9yvu8xim.json', 'output', 'file=/tmp/tmpxdlilnon/prophet_model-20221204225654.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:55 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:55 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/xt46ndck.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/89jge7a_.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=57190', 'data', 'file=/tmp/tmp5v0rfnlj/xt46ndck.json', 'init=/tmp/tmp5v0rfnlj/89jge7a_.json', 'output', 'file=/tmp/tmpfy_zfqlo/prophet_model-20221204225656.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:56 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:56 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/41_c5_sy.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp5v0rfnlj/rgfowh9c.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=1476', 'data', 'file=/tmp/tmp5v0rfnlj/41_c5_sy.json', 'init=/tmp/tmp5v0rfnlj/rgfowh9c.json', 'output', 'file=/tmp/tmpe69r0bj2/prophet_model-20221204225657.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "22:56:57 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:56:57 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 12-04 22:56:58] {3343} INFO -  at 54.8s,\testimator prophet's best error=0.0433,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 54.8s,\testimator prophet's best error=0.0433,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:58] {3166} INFO - iteration 113, current learner xgboost\n",
            "INFO:flaml.automl:iteration 113, current learner xgboost\n",
            "[flaml.automl: 12-04 22:56:58] {3343} INFO -  at 55.0s,\testimator xgboost's best error=0.0225,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 55.0s,\testimator xgboost's best error=0.0225,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:58] {3166} INFO - iteration 114, current learner rf\n",
            "INFO:flaml.automl:iteration 114, current learner rf\n",
            "[flaml.automl: 12-04 22:56:58] {3343} INFO -  at 55.1s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 55.1s,\testimator rf's best error=0.0162,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:58] {3166} INFO - iteration 115, current learner arima\n",
            "INFO:flaml.automl:iteration 115, current learner arima\n",
            "[flaml.automl: 12-04 22:56:59] {3343} INFO -  at 55.4s,\testimator arima's best error=0.0176,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 55.4s,\testimator arima's best error=0.0176,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:59] {3166} INFO - iteration 116, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 116, current learner extra_tree\n",
            "[flaml.automl: 12-04 22:56:59] {3343} INFO -  at 55.5s,\testimator extra_tree's best error=0.0195,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 55.5s,\testimator extra_tree's best error=0.0195,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:56:59] {3166} INFO - iteration 117, current learner sarimax\n",
            "INFO:flaml.automl:iteration 117, current learner sarimax\n",
            "[flaml.automl: 12-04 22:57:03] {3343} INFO -  at 60.2s,\testimator sarimax's best error=0.0185,\tbest estimator rf's best error=0.0162\n",
            "INFO:flaml.automl: at 60.2s,\testimator sarimax's best error=0.0185,\tbest estimator rf's best error=0.0162\n",
            "[flaml.automl: 12-04 22:57:03] {3602} INFO - retrain rf for 0.0s\n",
            "INFO:flaml.automl:retrain rf for 0.0s\n",
            "[flaml.automl: 12-04 22:57:03] {3609} INFO - retrained model: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',\n",
            "                      max_depth=None, max_features=1.0, max_leaf_nodes=21,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, n_estimators=7, n_jobs=-1,\n",
            "                      oob_score=False, random_state=None, verbose=0,\n",
            "                      warm_start=False)\n",
            "INFO:flaml.automl:retrained model: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',\n",
            "                      max_depth=None, max_features=1.0, max_leaf_nodes=21,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, n_estimators=7, n_jobs=-1,\n",
            "                      oob_score=False, random_state=None, verbose=0,\n",
            "                      warm_start=False)\n",
            "[flaml.automl: 12-04 22:57:03] {2901} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 12-04 22:57:03] {2902} INFO - Time taken to find the best model: 32.462651014328\n",
            "INFO:flaml.automl:Time taken to find the best model: 32.462651014328\n"
          ]
        }
      ],
      "source": [
        "from flaml import AutoML\n",
        "\n",
        "train_NVDA[\"Date\"] = pd.to_datetime(train_NVDA[\"Date\"])\n",
        "\n",
        "\n",
        "automl = AutoML()\n",
        "settings = {\n",
        "    \"time_budget\": 60,\n",
        "    \"metric\": 'mape',\n",
        "    \"task\": 'ts_forecast',\n",
        "    'log_file_name': 'Stock_Price.log',\n",
        "    'eval_method': 'auto',\n",
        "    'seed': 636362\n",
        "}\n",
        "automl.fit(dataframe = train_NVDA2,label = 'Price', **settings, period = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = automl.predict(x_test)    # Prediction using the model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x_test2.Date, y_test, label='Actual level')\n",
        "plt.plot(x_test.Date, y_pred, label='FLAML forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "9fgjoP9cNpFa",
        "outputId": "12f949c9-abfd-466f-ac22-952af03afd86"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6114eb8b80>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kwx9e1xLonpU",
        "QwpVZhrUobJV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}